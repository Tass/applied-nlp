#+AUTHOR: Simon Hafner
#+TITLE: anlp homework #4

* Tennis

#+BEGIN_SRC bash
classify --train tennis/train --eval tennis/test
Accuracy: 69.23076923076923
#+END_SRC

* Classification
  The best score seems to be 0.46. Overfitting included.

  | Accuracy | Cost |
  |----------+------|
  |    82.20 | 0.46 |
  |    82.17 | 0.54 |
  |    82.15 | 0.44 |
  |    82.15 | 0.48 |
  |    82.15 | 0.50 |


#+BEGIN_SRC bash
seq 0 0.02 1 | xargs -n1 --replace=foo nak classify \
 --train out/ppa.basic.training --eval out/ppa.basic.devset -c foo
#+END_SRC

[[file:basic_graph.pdf]]

** Classification Data :noexport:
  #+TBLNAME: basic
  |          Accuracy | Cost |
  |-------------------+------|
  | 82.19856400099034 | 0.46 |
  | 82.17380539737559 | 0.54 |
  | 82.14904679376083 | 0.44 |
  | 82.14904679376083 | 0.48 |
  | 82.14904679376083 | 0.50 |
  | 82.14904679376083 | 0.56 |
  | 82.12428819014607 | 0.52 |
  | 82.12428819014607 | 0.62 |
  | 82.09952958653132 | 0.70 |
  | 82.09952958653132 | 0.76 |
  | 82.09952958653132 | 0.86 |
  | 82.07477098291656 | 0.42 |
  | 82.07477098291656 | 0.64 |
  | 82.07477098291656 | 0.72 |
  | 82.07477098291656 | 0.74 |
  | 82.07477098291656 | 0.84 |
  | 82.07477098291656 | 0.88 |
  | 82.05001237930180 | 0.60 |
  | 82.05001237930180 | 0.66 |
  | 82.05001237930180 | 0.78 |
  | 82.05001237930180 | 0.90 |
  | 82.05001237930180 | 0.98 |
  | 82.02525377568705 | 0.68 |
  | 82.02525377568705 | 0.80 |
  | 82.00049517207229 | 0.58 |
  | 82.00049517207229 | 1.00 |
  | 81.97573656845753 | 0.40 |
  | 81.97573656845753 | 0.96 |
  | 81.95097796484279 | 0.32 |


  #+NAME: basic_graph
  #+BEGIN_SRC R :var table=basic :file basic_graph.pdf :results graphics
  library(ggplot2)
  print(ggplot(table, aes(x=Cost, y=Accuracy)) + geom_line())
  #+END_SRC
  
  #+RESULTS: basic_graph
  [[file:basic_graph.pdf]]


* Extending the fun
** Mutual Information Clustering
   The idea behind the mutual information clustering is not entirely
   different from a compression algorithm. But in this case, we can
   accept the loss of information which is perceived less important.
   The clustering is generated based on mutual information. The paper
   does not explain what this mutual information is, but based on the
   referenced paper, which uses n-grams to achieve the cluster, I
   assume this paper uses n-grams as well. Using the four head words
   as mutual information basis would lead to overusage of information.
   
   The clustering is generated by taking the C most frequent words,
   Brown 1992 proposed this for speed reasons, and all remaining words
   are added one-by-one by creating a new class for them and merging
   the two most similar classes. The added class is not necessary one
   of them, as words like `the` and `a`,  which occur frequently but
   in the same places are likely to go to the same cluster.

   After C classes remain, all of those classes are merged again to
   form a single class. Then the merging is unrolled and from the
   merging paths, a binary tree is created. The path to a word is
   encoded by a sequence containing 'go left' or 'go right', denoted
   as a bitset. It is then possible to use each single decision as a
   feature for machine learning.

** New Features
It is possible to encode more linguistic knowledge into this than
just the strings. Let's do it.
   
*** Numbers
    A Simple regex that checks if the first element of the noun is a
    non-word. I found a `%` marked as noun (not uncommon, about 4% of
    the examples), which is likely part of a number. Numbers are one
    combined category, and without this feature, the machine learning
    algorithm is not aware of this fact.
    
*** Capsed Words
    The regular expressions for this features are sensitive to order
    of applying, it's possible to catch more this way. This feature
    helps recognizing named entities.

*** Pronouns
    Also added are pronouns, as they usually reference Named Entities.
    I copied a list from Wikipedia [1].
    
[1] \url{http://en.wikipedia.org/wiki/English_pronouns}
*** Stems
    The stemmer shipped with anlp is integrated to stem the verb/noun
    and add it to the feature set. This groups the same word together
    under one value, where the classifier previously had no idea that
    `join` and `joined` were the same verb.
    
*** Combined Stems
    I improve the combined words in such a way that it uses stems
    instead of words, because of the exponential increase of possible
    values. If we stem before combining, more values will be
    equivalent.
    
*** Bitvectors
    The bitvectors are added as single bits (as described in the
    paper) and as top X bits.

    

** Performance
Because the extended features are going well with low numbers, I added
some more samples.

[[file:performance_graph.pdf]]

| Features | Accuracy |
|----------+----------|
| Extended |    81.79 |
| Basic    |    82.18 |

Too much overfitting. â˜¹

*** Data                                                         :noexport:

#+BEGIN_SRC bash
seq 0.05 0.05 3 | xargs -P5 -n1 -I foo nice -n 15 bash -c 'for f in training devset; do ../../../applied-nlp/bin/anlp run appliednlp.classify.PpaFeatures -e -b ppa/bitstrings ppa/$f  > out/ppa.extended.foo.$f; done; ../../bin/nak classify -c foo --train out/ppa.extended.foo.training --eval out/ppa.extended.foo.devset'
#+END_SRC

And a little patch to nak to output the cost before the accuracy.

#+TBLNAME: performance
|          Accuracy | Cost | Features |
|-------------------+------+----------|
| 82.44615003713791 |  0.1 | Extended |
| 82.34711562267888 | 0.09 | Extended |
| 82.34711562267888 | 0.08 | Extended |
| 82.32235701906413 | 0.06 | Extended |
| 82.29759841544937 | 0.03 | Extended |
| 82.27283981183461 | 0.07 | Extended |
| 82.24808120821986 | 0.11 | Extended |
|  82.2233226046051 | 0.05 | Extended |
|  82.2233226046051 | 0.05 | Extended |
| 82.19856400099034 | 0.55 | Basic    |
| 82.17380539737559 | 0.45 | Basic    |
| 82.17380539737559 | 0.04 | Extended |
| 82.14904679376083 |  0.5 | Basic    |
| 82.14904679376083 | 0.15 | Extended |
| 82.14904679376083 | 0.25 | Extended |
| 82.14904679376083 | 0.12 | Extended |
| 82.14904679376083 | 0.15 | Extended |
| 82.12428819014607 | 0.13 | Extended |
| 82.09952958653132 |  0.7 | Basic    |
| 82.09952958653132 | 0.02 | Extended |
| 82.09952958653132 | 0.14 | Extended |
| 82.07477098291656 | 0.75 | Basic    |
| 82.07477098291656 | 0.85 | Basic    |
| 82.07477098291656 | 0.16 | Extended |
|  82.0500123793018 |  0.6 | Basic    |
|  82.0500123793018 | 0.65 | Basic    |
|  82.0500123793018 |  0.9 | Basic    |
|  82.0500123793018 | 1.15 | Basic    |
|  82.0500123793018 | 1.45 | Basic    |
|  82.0500123793018 | 0.17 | Extended |
| 82.02525377568705 |  0.8 | Basic    |
| 82.02525377568705 | 1.05 | Basic    |
| 82.02525377568705 |  1.2 | Basic    |
| 82.02525377568705 | 1.25 | Basic    |
| 82.02525377568705 |  1.3 | Basic    |
| 82.02525377568705 | 1.35 | Basic    |
| 82.02525377568705 |  1.4 | Basic    |
| 82.02525377568705 |  1.6 | Basic    |
| 82.00049517207229 |  1.0 | Basic    |
| 82.00049517207229 |  1.1 | Basic    |
| 81.97573656845753 |  0.4 | Basic    |
| 81.97573656845753 | 0.95 | Basic    |
| 81.97573656845753 | 0.18 | Extended |
| 81.95097796484279 | 1.65 | Basic    |
| 81.95097796484279 |  0.2 | Extended |
| 81.95097796484279 |  0.2 | Extended |
| 81.95097796484279 | 0.19 | Extended |
| 81.92621936122802 |  1.5 | Basic    |
| 81.92621936122802 | 1.55 | Basic    |
| 81.92621936122802 |  1.7 | Basic    |
| 81.92621936122802 | 0.35 | Extended |
| 81.90146075761328 |  0.3 | Basic    |
| 81.90146075761328 | 0.35 | Basic    |
| 81.87670215399851 |  0.3 | Extended |
| 81.85194355038375 | 1.75 | Basic    |
| 81.85194355038375 |  1.8 | Basic    |
| 81.85194355038375 | 1.85 | Basic    |
| 81.85194355038375 | 2.25 | Basic    |
| 81.80242634315424 | 2.15 | Basic    |
|  81.7776677395395 |  1.9 | Basic    |
|  81.7776677395395 |  2.1 | Basic    |
|  81.7776677395395 |  2.2 | Basic    |
| 81.75290913592474 | 1.95 | Basic    |
| 81.75290913592474 |  2.0 | Basic    |
| 81.75290913592474 |  2.3 | Basic    |
| 81.75290913592474 | 2.35 | Basic    |
| 81.72815053230997 |  2.4 | Basic    |
| 81.70339192869523 | 0.25 | Basic    |
| 81.70339192869523 | 2.05 | Basic    |
| 81.70339192869523 | 2.45 | Basic    |
| 81.70339192869523 |  2.5 | Basic    |
| 81.70339192869523 | 2.55 | Basic    |
| 81.70339192869523 |  0.4 | Extended |
| 81.65387472146571 | 2.65 | Basic    |
| 81.65387472146571 | 0.45 | Extended |
| 81.62911611785096 |  2.7 | Basic    |
|  81.6043575142362 |  2.6 | Basic    |
|  81.6043575142362 |  2.9 | Basic    |
| 81.57959891062144 |  0.2 | Basic    |
| 81.57959891062144 | 2.75 | Basic    |
| 81.57959891062144 |  2.8 | Basic    |
| 81.57959891062144 |  0.5 | Extended |
| 81.55484030700669 | 2.95 | Basic    |
| 81.50532309977717 | 2.85 | Basic    |
| 81.48056449616242 | 0.15 | Basic    |
| 81.48056449616242 |  3.0 | Basic    |
| 81.45580589254766 | 0.01 | Extended |
| 81.38153008170339 | 0.55 | Extended |
| 81.38153008170339 |  0.6 | Extended |
| 81.38153008170339 | 0.65 | Extended |
| 81.20821985640009 |  1.1 | Extended |
| 81.18346125278534 |  0.7 | Extended |
| 81.18346125278534 | 0.75 | Extended |
| 81.15870264917059 |  0.9 | Extended |
| 81.15870264917059 |  1.0 | Extended |
| 81.13394404555582 |  0.8 | Extended |
| 81.13394404555582 | 0.85 | Extended |
| 81.13394404555582 | 0.95 | Extended |
| 81.13394404555582 |  1.2 | Extended |
| 81.10918544194108 | 1.05 | Extended |
| 81.10918544194108 | 1.15 | Extended |
| 81.10918544194108 | 1.25 | Extended |
| 80.93587521663778 | 1.35 | Extended |
| 80.93587521663778 |  1.5 | Extended |
| 80.91111661302303 |  1.3 | Extended |
| 80.91111661302303 | 1.55 | Extended |
| 80.88635800940827 |  1.4 | Extended |
| 80.86159940579351 | 1.65 | Extended |
| 80.83684080217876 |  0.1 | Basic    |
|   80.812082198564 |  1.8 | Extended |
| 80.73780638771973 | 1.45 | Extended |
| 80.73780638771973 |  1.7 | Extended |
| 80.66353057687546 |  1.6 | Extended |
|  80.6387719732607 | 1.75 | Extended |
| 80.61401336964596 | 1.85 | Extended |
| 80.56449616241645 |  1.9 | Extended |
| 80.49022035157218 | 2.05 | Extended |
| 80.49022035157218 |  2.2 | Extended |
| 80.44070314434266 | 1.95 | Extended |
|  80.4159445407279 |  2.0 | Extended |
| 80.39118593711315 | 2.45 | Extended |
| 80.34166872988364 |  2.1 | Extended |
| 80.34166872988364 | 2.15 | Extended |
| 80.34166872988364 | 2.35 | Extended |
| 80.34166872988364 |  2.6 | Extended |
| 80.31691012626888 |  2.3 | Extended |
| 80.31691012626888 |  2.5 | Extended |
| 80.29215152265412 |  2.4 | Extended |
| 80.29215152265412 | 2.65 | Extended |
| 80.26739291903937 | 2.85 | Extended |
| 80.24263431542461 | 2.25 | Extended |
| 80.24263431542461 |  2.8 | Extended |
| 80.24263431542461 |  2.9 | Extended |
| 80.21787571180985 | 2.55 | Extended |
| 80.14359990096558 | 2.75 | Extended |
| 80.09408269373607 |  2.7 | Extended |
| 80.09408269373607 | 2.95 | Extended |
| 80.01980688289181 |  3.0 | Extended |
| 79.64842782867046 | 0.05 | Basic    |


#+NAME performance_graph
#+BEGIN_SRC R :var table=performance :file performance_graph.pdf :results graphics
library(ggplot2)
print(ggplot(table, aes(x=Cost, y=Accuracy, color=Features)) + geom_line())
#+END_SRC

#+RESULTS:
[[file:performance_graph.pdf]]

* Confidence
As some machine learning models in production interact with a human in
the end (say spam), feedback could be encouraged on not so confident
examples. For development, the examples which scored a low confidence
are interesting, as they show where the problems with the model lie,
where it cannot make a well-founded decision. Is there a feature that
could be integrated to give more information to those cases?

** Basic Featureset
| Confidence | Accuracy |
|------------+----------|
| High       |    98.64 |
| Mid        |    85.85 |
| Low        |    62.02 |

** Extended Featureset
| Confidence |           Accuracy |
|------------+--------------------|
| High       | 0.9883833494675702 |
| Mid        | 0.8498062015503876 |
| Low        | 0.6153100775193798 |

* SMS Spam
A slightly newer phenomenon than email spam is SMS spam. I've found a
database [3] of some spam messages (only around 800) with a lot more ham
in it. This creates a slight imbalance, so I cut the size of the ham
down to spam. This is feasible with non-continuous features as
applied here, as the message size is small.

[3] \url{http://archive.ics.uci.edu/ml/machine-learning-databases/00228/}

** Features
Given the small size of an SMS, an unigram feature for each word is
feasible, but will likely not result in anything useful.

Weird to use features that test if something is non-grammatical and if
yes, it's likely not spam. We used to do the opposite with email spam.

*** Length of the text
A Spam text needs more to bring its message over, it's very hard to
advertise something in 20 characters. I group them by lengths of 10.

*** Contains a number
If it's about money, it will contain a number. A number must contain
at least two digits in succession, to rule out shortcuts like `gr8
night!`

*** Sentence markers anywhere but the end
Often people do not use punctuation anywhere but in the last few
characters. May correlate with the length.

*** Does contain ...
Some people seem to use ... pretty often, while spammers do not use
it at all.

*** Uppercase anywhere but the first character
The first character is uppercased by a lot of mobile phones. This
does also include characters after periods.

** Results
An interesting metric for this problem would be false positives, as
it's easier to deal with an occasional spam mail than needing to go
through all of the messages in the spam folder.

The paper using the SMS corpus achieves an accuracy of over 97.5%
with 13% spam and 86% ham. For comparable values, I run the
classifier also with the full dataset.

[[file:sms_graph.pdf]]

The accuracy comes close to what the paper [4] achieves, without any
tokenization.

| Collection | Accuracy |
|------------+----------|
| full       |    97.27 |
| adjusted   |    93.58 |


*** Data :noexport:

#+TBLNAME: sms
| Cost |          Accuracy | Collection |
|------+-------------------+------------|
|  1.0 |  97.2520107238606 | full       |
|  1.1 | 97.18498659517427 | full       |
|  1.2 | 97.18498659517427 | full       |
|  1.3 | 97.18498659517427 | full       |
|  1.4 | 97.18498659517427 | full       |
|  1.5 | 97.18498659517427 | full       |
|  1.6 | 97.18498659517427 | full       |
|  1.7 | 97.18498659517427 | full       |
|  1.8 | 97.18498659517427 | full       |
|  1.9 | 97.11796246648794 | full       |
|  2.0 | 97.11796246648794 | full       |
|  2.1 | 97.11796246648794 | full       |
|  2.2 | 97.11796246648794 | full       |
|  2.3 | 97.11796246648794 | full       |
|  2.4 | 97.11796246648794 | full       |
|  2.5 | 97.11796246648794 | full       |
|  2.7 | 97.11796246648794 | full       |
|  2.6 | 97.11796246648794 | full       |
|  2.8 | 97.11796246648794 | full       |
|  2.9 | 97.11796246648794 | full       |
|  3.0 | 97.11796246648794 | full       |
|  0.2 | 97.05093833780161 | full       |
|  0.5 | 97.05093833780161 | full       |
|  0.1 | 97.05093833780161 | full       |
|  0.3 | 97.05093833780161 | full       |
|  0.7 | 97.05093833780161 | full       |
|  0.6 | 97.05093833780161 | full       |
|  0.8 | 97.05093833780161 | full       |
|  0.9 | 97.05093833780161 | full       |
|  0.4 | 96.98391420911528 | full       |
|  0.2 |              94.5 | adjusted   |
|  0.1 |              94.5 | adjusted   |
|  0.3 |              94.5 | adjusted   |
|  0.4 |              94.5 | adjusted   |
|  0.5 |             94.25 | adjusted   |
|  0.6 |             94.25 | adjusted   |
|  0.9 |             93.75 | adjusted   |
|  0.7 |             93.75 | adjusted   |
|  0.8 |             93.75 | adjusted   |
|  1.0 |             93.75 | adjusted   |
|  1.1 |             93.75 | adjusted   |
|  1.2 |             93.75 | adjusted   |
|  1.3 |             93.75 | adjusted   |
|  1.4 |             93.75 | adjusted   |
|  1.5 |             93.75 | adjusted   |
|  1.7 |             93.75 | adjusted   |
|  1.6 |             93.75 | adjusted   |
|  1.8 |             93.75 | adjusted   |
|  1.9 |             93.75 | adjusted   |
|  2.0 |             93.75 | adjusted   |
|  2.1 |             93.75 | adjusted   |
|  2.3 |             93.75 | adjusted   |
|  2.2 |             93.75 | adjusted   |
|  2.4 |             93.75 | adjusted   |
|  2.5 |             93.75 | adjusted   |
|  2.7 |             93.75 | adjusted   |
|  2.6 |             93.75 | adjusted   |
|  2.8 |             92.25 | adjusted   |
|  2.9 |             92.25 | adjusted   |
|  3.0 |             92.25 | adjusted   |


#+NAME: sms_graph
#+BEGIN_SRC R :var table=sms :file sms_graph.pdf :results graphics
library(ggplot2)
print(ggplot(table, aes(x=Cost, y=Accuracy, color=Collection)) + geom_line())
#+END_SRC

#+RESULTS: sms_graph
[[file:sms_graph.pdf]]

** Confidence
The confidence levels indicate that it is certain in almost all cases.
I might even suggest tagging all in the low confidence section as
non-spam, as a false positive is more expensive than a false negative.

*** Adjusted Dataset
| Confidence | Accuracy |
|------------+----------|
| High       |     0.99 |
| Mid        |      1.0 |
| Low        |    81.63 |

*** Full Dataset
| Confidence | Accuracy |
|------------+----------|
| High       |      1.0 |
| Mid        |    98.63 |
| Low        |    93.17 |

[4] http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/doceng11.pdf
